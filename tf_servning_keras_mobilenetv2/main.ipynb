{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Deploying A Deep Learning Model in Keras MobileNet V2 and Heroku: A Step-by-Step Tutorial \n",
    "\n",
    "Today, we going to learn how to train a deep learning model and deploy it. It's important to understand the process of training a model in order to apply to your specific domain. As well, After the model is trained and ready to be used, the model need to be easily called via API. Therefore, I am going to walk you through the entire process and show you how after training a model we can with ease deploy to Heroku.\n",
    "\n",
    "I am going to divide the tutorial into 2 parts:\n",
    "\n",
    "**Part 1:**\n",
    "- Prepare data for training \n",
    "- Trained a deep learning model\n",
    "\n",
    "**Part 2:**\n",
    "- Serve the model with [Tensorflow Serving](https://www.tensorflow.org/serving/).\n",
    "- Deploy to [Heroku](https://www.heroku.com/).\n",
    "\n",
    "**In order to fully benefits from this blog:**\n",
    "- You should be familiar with python.\n",
    "- You should have some understanding of what deep learning and neural network are.\n",
    "\n",
    "**Here are the list of what we are going to use:**\n",
    "- [Keras 2.2](https://keras.io/)is a high-level neural networks API, written in Python and capable of running on top of TensorFlow.\n",
    "- [Tensorflow 1.11](https://www.tensorflow.org/) is an open-source machine learning library for research and production. Tensorflow is Google's attempt to put the power of Deep Learning into the hands of developers around the world.[2] As well, TensorFlow offers APIs for beginners and experts to develop for desktop, mobile, web, and cloud.\n",
    "- [Python 3.6](https://www.python.org/downloads/release/python-367/)\n",
    "- [scikit-image 0.14](https://scikit-image.org/)  is a collection of algorithms for image processing\n",
    "- [scikit-learn 0.19](http://scikit-learn.org/) Machine Learning in Python\n",
    "- [pillow 4.1](https://pillow.readthedocs.io/en/4.1.x/)  is the Python Imaging Library\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start let's answer some question that may come to your mind\n",
    "\n",
    "### Why Tensorflow?\n",
    "There are many reasons why Tensorflow should be selected as deep learning framework. I found that this github project ([easy-tensorflow](https://github.com/easy-tensorflow/easy-tensorflow#why-use-tensorflow)) answers the question 'why' very well and cover all the points I wanted to mention. \n",
    "\n",
    "### What is heroku? why heroku? \n",
    "Heroku is a platform as a service (PaaS) that enables developers to build, run, and operate applications entirely in the cloud. I am going to use Heroku because it's free to use for development and testing, easy to deploy (does not require much work), support many languages by default, and lastly I could not found much resources about deploying Tensorflow model to Heroku. Here is a nice article [An Introduction to Heroku](https://medium.com/@GoRadialspark/an-introduction-to-heroku-c11c6fcbffa)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data for training\n",
    "\n",
    "### why do we need to prepare data for training?\n",
    "\n",
    "TODO \n",
    "\n",
    "For the sake of simplicity, I am going to use the Fashion-MNIST dataset because it is already optimized and labeled for a classification problem. \n",
    "Read more about the Fashion-MNIST dataset in this paper [here](https://arxiv.org/abs/1708.07747).\n",
    "To download dataset and see other examples [here](https://github.com/zalandoresearch/fashion-mnist)\n",
    "\n",
    "The Fashion-MNIST dataset has 70,000 grayscale, \n",
    "(28x28px) images separated into the following categories:\n",
    "\n",
    "|Label|Description|  \n",
    "|-  |      -      |\n",
    "| 0 | T-shirt/top | \n",
    "| 1 | Trouser     | \n",
    "| 2 | Pullover    |  \n",
    "| 3 | Dress       | \n",
    "| 4 | Coat        | \n",
    "| 5 | Sandal      | \n",
    "| 6 | Shirt       |\n",
    "| 7 | Sneaker     | \n",
    "| 8 | Bag         | \n",
    "| 9 | Ankle boot  | \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's start downloading the dataset.\n",
    "Fortunately, many deep learning (DL) frameworks support Fashion-MNIST dataset out of the box, including Keras in our case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets.fashion_mnist import load_data\n",
    "\n",
    "# Load the fashion-mnist train data and test data\n",
    "(x_train, y_train), (x_test, y_test) = load_data()\n",
    "\n",
    "print(\"x_train shape:\", x_train.shape, \"y_train shape:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default `load_data()` returns training and testing dataset. It is essential to split the dataset into training and testing.    \n",
    "**Train data**: This data to train the Neural Network (NN).   \n",
    "**Test**: To valid the Neural Network during the training phase, by tuning and re-adjust the hyperparameters. Hyperparameter is a parameter whose value is set before the learning process begins.\n",
    "\n",
    "**However sometime you see Train, Valid and Test dataset, why?**\n",
    "\n",
    "Glad you ask!\n",
    "\n",
    "After training a Neural Network, we run the trained model against our validation dataset to make sure that the model is generalized and is not overfitting.\n",
    "\n",
    "**What is overfitting? :)**\n",
    "\n",
    "Overfitting basically means a model predict the right result when it tests against the train data, but it fails otherwise. However, if a model predicts the incorrectly result for the train data, then it is called underfitting. Here is a nice explanation of [overfitting and underfitting](https://medium.com/greyatom/what-is-underfitting-and-overfitting-in-machine-learning-and-how-to-deal-with-it-6803a989c76).\n",
    "\n",
    "\n",
    "Thus, we use the validation to detect overfitting or underfitting. But, most of the time we train the model multiple times in order to have higher score in the train and valid datasets. Although, this process of training multiple is required in many use cases, we need to be carefully that we don't end up overfitting in validation set. To make sure the both sets were trained properly, we use the third dataset (Test)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper function to display imags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "def show_images(images):\n",
    "    \"\"\"\n",
    "    images : numpy arrays\n",
    "    \"\"\"\n",
    "    n_images = len(images)\n",
    "    titles = ['(%d)' % i for i in range(1, n_images + 1)]\n",
    "    num = 5\n",
    "    iter_num = np.ceil(n_images / num).astype(int)\n",
    "    for i in range(iter_num):\n",
    "        fig = plt.figure()\n",
    "        sub_images = images[i * num:num * (i + 1)]\n",
    "        sub_titles = titles[i * num:num * (i + 1)]\n",
    "        for n, (image, title) in enumerate(zip(sub_images, sub_titles)):\n",
    "            a = fig.add_subplot(1, np.ceil(len(sub_images)), n + 1)\n",
    "            if image.ndim == 2:\n",
    "                plt.gray()\n",
    "            a.set_title(title, fontsize=15)\n",
    "            plt.imshow(image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show samples of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(x_train[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data normalization\n",
    "Normalize the data dimensions so that they are of approximately the same scale.In general, normalization makes very deep NN easier to train, special in Convolutional and Recurrent neural network.\n",
    "\n",
    "Here is a nice explanation [video](https://www.coursera.org/lecture/deep-neural-network/normalizing-activations-in-a-network-4ptp2) and an [article](https://medium.com/@darrenyaoyao.huang/why-we-need-normalization-in-deep-learning-from-batch-normalization-to-group-normalization-d06ea0e59c17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_x_train = x_train.astype('float32') / 255\n",
    "norm_x_test = x_test.astype('float32') / 255\n",
    "# dsiplay images\n",
    "show_images(norm_x_train[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert labels (y_train and y_test) to one hot encoding\n",
    "A one hot encoding is a representation of categorical variables as binary vectors.  \n",
    "[Here is the full explanation](https://machinelearningmastery.com/how-to-one-hot-encode-sequence-data-in-python/) If you would like to have a deep understanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "encoded_y_train = to_categorical(y_train, num_classes=10, dtype='float32')\n",
    "encoded_y_test = to_categorical(y_test, num_classes=10, dtype='float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resize images & convert to 3 channel (RGB)\n",
    "\n",
    "[MobileNet V2](https://keras.io/applications/#mobilenetv2) model accepts one of the following formats: (96, 96), (128, 128), (160, 160),(192, 192), or (224, 224). In addition, the image has to be 3 channel (RGB) format. Therefore, We need to resize & convert our images. from (28 X 28) to (96 X 96 X 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from skimage.transform import resize\n",
    "\n",
    "target_size = 96\n",
    "\n",
    "def preprocess_image(x):\n",
    "    # Resize the image to have the shape of (96,96)\n",
    "    x = resize(x, (target_size, target_size),\n",
    "            mode='constant',\n",
    "            anti_aliasing=False)\n",
    "    \n",
    "    # convert to 3 channel (RGB)\n",
    "    x = np.stack((x,)*3, axis=-1) \n",
    "    \n",
    "    # Make sure it is a float32, here is why \n",
    "    # https://www.quora.com/When-should-I-use-tf-float32-vs-tf-float64-in-TensorFlow\n",
    "    return x.astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the previous code in all our data data, it may eat up a lot of memory resources; therefore, we are going to use generator.   \n",
    "[Python Generator](https://www.programiz.com/python-programming/generator) is a function that returns an object (iterator) which we can iterate over (one value at a time)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "def load_data_generator(x, y, batch_size=64):\n",
    "    num_samples = x.shape[0]\n",
    "    while 1:  # Loop forever so the generator never terminates\n",
    "        try:\n",
    "            shuffle(x)\n",
    "            for i in range(0, num_samples, batch_size):\n",
    "                x_data = [preprocess_image(im) for im in x[i:i+batch_size]]\n",
    "                y_data = y[i:i + batch_size]\n",
    "            \n",
    "                # convert to numpy array since this what keras required\n",
    "                yield shuffle(np.array(x_data), np.array(y_data))\n",
    "        except Exception as err:\n",
    "            print(err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a Deep Learning model\n",
    "\n",
    "There are many technique of train the model, today I am going to convert one of them, and I believe that it is one of the most important method or strategy, it is called Transfer Learning.\n",
    "\n",
    "### Transfer Learning\n",
    "Transfer learning in deep learning means to transfer a knowledge from one domain to a similar one. In our example, I have chosen MobileNet V2 model because it's faster to train and small in size. And most important, MobileNet is pre-trained with [ImageNet dataset](http://www.image-net.org/).\n",
    "\n",
    "> ImageNet is an image dataset organized according to the WordNet hierarchy. Each meaningful concept in WordNet, possibly described by multiple words or word phrases, is called a \"synonym set\" or \"synset\". There are more than 100,000 synsets in WordNet, majority of them are nouns (80,000+). In ImageNet, we aim to provide on average 1000 images to illustrate each synset. Images of each concept are quality-controlled and human-annotated.\n",
    "\n",
    "Since our dataset is kind of subset of ImageNet dataset, then we are going to transfer the knowledge of this model onto our datasets. And if you feel like to dive into it more, which I encourage you, here is a nice article that explain it in more details [A Gentle Introduction to Transfer Learning for Deep Learning](https://machinelearningmastery.com/transfer-learning-for-deep-learning/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.applications.mobilenetv2 import MobileNetV2\n",
    "from keras.layers import Dense, Input, Dropout\n",
    "from keras.models import Model\n",
    "\n",
    "def build_model( ):\n",
    "    input_tensor = Input(shape=(target_size, target_size, 3))\n",
    "    base_model = MobileNetV2(\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        input_tensor=input_tensor,\n",
    "        input_shape=(target_size, target_size, 3),\n",
    "        pooling='avg')\n",
    "\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = True  # trainable has to be false in order to freeze the layers\n",
    "        \n",
    "    op = Dense(256, activation='relu')(base_model.output)\n",
    "    op = Dropout(.25)(op)\n",
    "    \n",
    "    ##\n",
    "    # softmax: calculates a probability for every possible class.\n",
    "    #\n",
    "    # activation='softmax': return the highest probability;\n",
    "    # for example, if 'Coat' is the highest probability then the result would be \n",
    "    # something like [0,0,0,0,1,0,0,0,0,0] with 1 in index 5 indicate 'Coat' in our case.\n",
    "    ##\n",
    "    output_tensor = Dense(10, activation='softmax')(op)\n",
    "\n",
    "    model = Model(inputs=input_tensor, outputs=output_tensor)\n",
    "\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below code is important to understand when working using Transfer Learning as a technique.\n",
    "```\n",
    "for layer in base_model.layers:\n",
    "  # trainable has to be false in order to freeze the layers\n",
    "  layer.trainable = False # or True\n",
    "```\n",
    "\n",
    "As using a  pre-trained model (e.g. MobileNetV2 in our case), you need to pay close a attention  to a concept call Fine Tuning.\n",
    "\n",
    "> **'Fine Tuning'**, generally, is when we freeze the weights of all the layers of the pre-trained neural networks (on dataset A [e.g. ImageNet]) except the penultimate layer and train the neural network on dataset B [e.g. Fashion-MNIST], just to learn the representations on the penultimate layer. We usually replace the last (softmax) layer with another one of our choice (depending on the number of outputs we need for the new problem.[3]\n",
    "\n",
    "In our case, we have 10 classes, so we have the following  \n",
    "`output_tensor = Dense(10, activation='softmax')(op)`\n",
    "\n",
    "**When do we use need Fine Tuning?**\n",
    "- When you have small datasets (e.g. few 1000s)\n",
    "- When the dataset used to train the pre-trained model is very  similar or the same as the new dataset. \n",
    "\n",
    "An obvious use case to use Fine Tuning is when building a model predicts only sub classes (20) out of 1000 of ImageNet dataset as dataset B (sub of ImageNet) is a subset of dataset A (ImageNet)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "model = build_model()\n",
    "model.compile(optimizer=Adam(),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we build and compile the model. Some definition use when compile a model:\n",
    "> The Adam optimization algorithm is an extension to stochastic gradient descent that has recently seen broader adoption for deep learning applications in computer vision and natural language processing.[4]\n",
    "\n",
    "> A loss function (categorical_crossentropy) is a measure of how good a prediction model does in terms of being able to predict the expected outcome. [5]\n",
    "\n",
    "> categorical_accuracy is a metric function that is used to judge the performance of your model.[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = load_data_generator(norm_x_train, encoded_y_train, batch_size=64)\n",
    "\n",
    "model.fit_generator(\n",
    "    generator=train_generator,\n",
    "    steps_per_epoch=5,\n",
    "    verbose=1,\n",
    "    epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is an essential to the understand the following when training any deep leaning model.\n",
    "> Epoch is when an entire dataset is passed forward and backward through the neural network only once. [7]\n",
    "\n",
    "> Batch Size is the total number of training examples present in a single batch [7]. And it goes a long with python generate mention previously \n",
    "\n",
    "> Iterations (steps_per_epoch)  is the number of batches needed to complete one epoch [7]. \n",
    "And to have more details understand, I suggest read the following article Epoch vs Batch Size vs Iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test\n",
    "94% I got after 5 epoch of training, now I would like to see how I did in the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator = load_data_generator(norm_x_test, encoded_y_test, batch_size=64)\n",
    "model.evaluate_generator(generator=test_generator,\n",
    "                         steps=900,\n",
    "                         verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It was 86%, seems reasonable for the amount I spent to train, 1 hour in CPU machine.\n",
    "\n",
    "**Things to you could try to improve the accuracy**\n",
    "\n",
    "- Choose more epoch, 10 as an example\n",
    "- Try freeze the layers layer.trainable = False. you could also get less.\n",
    "- Choose bigger batch_size, 128 as an example\n",
    "- Select different optimizer, Nadam, for instance. However changing the optimizer sometime does not give mush improving.\n",
    "\n",
    "## Save the model\n",
    "Make sure you save the model, because we are going to use in next part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_name = \"tf_serving_keras_mobilenetv2\"\n",
    "model.save(f\"models/{model_name}.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Makes Model ready to tensorflow serving\n",
    "\n",
    "### Tensorflow serving \n",
    "[TensorFlow Serving](https://www.tensorflow.org/serving/overview) is a flexible, high-performance serving system for machine learning models, designed for **production** environments.\n",
    "\n",
    "\n",
    "#### Load the saved model from Part 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model(f\"models/{model_name}.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build & Save model to be tensorflow serving ready\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "# Import the libraries needed for saving models\n",
    "# Note that in some other tutorials these are framed as coming from tensorflow_serving_api which is no longer correct\n",
    "from tensorflow.python.saved_model import builder as saved_model_builder\n",
    "from tensorflow.python.saved_model import tag_constants, signature_constants, signature_def_utils_impl\n",
    "\n",
    "# images will be the input key name\n",
    "# scores will be the out key name\n",
    "prediction_signature = tf.saved_model.signature_def_utils.predict_signature_def(\n",
    "    {\n",
    "    \"images\": model.input\n",
    "    }, {\n",
    "    \"scores\": model.output\n",
    "    })\n",
    "\n",
    "# export_path is a directory in which the model will be created\n",
    "export_path = os.path.join(\n",
    "    tf.compat.as_bytes('models/export/{}'.format(model_name)),\n",
    "    tf.compat.as_bytes('1'))\n",
    "\n",
    "builder = saved_model_builder.SavedModelBuilder(export_path)\n",
    "\n",
    "sess = keras.backend.get_session()\n",
    "\n",
    "# Add the meta_graph and the variables to the builder\n",
    "builder.add_meta_graph_and_variables(\n",
    "    sess, [tag_constants.SERVING],\n",
    "    signature_def_map={\n",
    "        'prediction': prediction_signature,\n",
    "    })\n",
    "# save the graph\n",
    "builder.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up Heroku & Docker\n",
    "Nice work, almost there, now we are going to deploy our model to heroku.\n",
    "\n",
    "[Heroku](https://www.heroku.com/) is a cloud platform as a service supporting several programming languages.\n",
    "[docker](https://www.docker.com/) allows us to package all the necessary libraries and programer into a container. Here is a nice [Introduction to Containers, VMs and Docker](https://medium.freecodecamp.org/a-beginner-friendly-introduction-to-containers-vms-and-docker-79a9e3e119b)\n",
    "\n",
    "\n",
    "- [Install docker for macOS and windows](https://www.docker.com/products/docker-desktop)\n",
    "- A little more work for Ubuntu users but still straightforward [Install docker for Ubuntu](https://docs.docker.com/install/linux/docker-ce/ubuntu/#upgrade-docker-ce)\n",
    "- [Signup to Heroku](https://signup.heroku.com/)\n",
    "- [Install heroku-cli](https://devcenter.heroku.com/articles/heroku-cli#download-and-install)\n",
    "\n",
    "### After you have installed docker and heroku-cli.\n",
    "\n",
    "Run the following to make sure docker & heroku have been installed correctly\n",
    "```\n",
    "> docker ps \n",
    "CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES\n",
    "\n",
    "> heroku --version\n",
    "heroku/7.18.3 darwin-x64 node-v10.12.0\n",
    "\n",
    "# make sure you have logged in to your heroku account\n",
    "heroku login\n",
    "# Output should have:   \n",
    "Logged in as xxxxx@xxx.xx\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy the model to Heroku\n",
    "\n",
    "#### Download tensorflow serving image from `hub.docker.com`\n",
    "Because tensorflow serving docker image was not optimized for heroku. \n",
    "\n",
    "I have created a dockerfile that following heroku instructure.\n",
    "cleck [here](https://github.com/malnakli/ML/tf_servning_keras_mobilenetv2/Dockerfile) to look at.\n",
    "Also I have pushed the a docker image that ready to deploy to heroku, which already have the trained model. \n",
    "`docker pull malnakli/ml:tf-serving-heroku-1.11`\n",
    "\n",
    "However, I will walk you through how to do build the image that has your trained model\n",
    "\n",
    "Run the following:\n",
    "And make sure you are in the right folder before running any command `cd ML/tf_servning_keras_mobilenetv2`\n",
    "\n",
    "Build docker image:\n",
    "`docker build -t tf-serving-heroku-1.11 .`\n",
    "\n",
    "Once the image build. you can run it locally if you would like, otherwise go to deploy section.\n",
    "`docker run -p 8501:8501 -e PORT=8501 -t tf-serving-heroku-1.11`\n",
    "\n",
    "If you see the following the last output, then it works.\n",
    "```\n",
    "2018-10-27 21:17:47.515120: I tensorflow_serving/model_servers/server.cc:301] Exporting HTTP/REST API at:localhost:8501 ...\n",
    "```\n",
    "#### Deploy\n",
    "\n",
    "##### Log in to Container Registry:\n",
    "`heroku container:login`\n",
    "\n",
    "##### Create a heroku app\n",
    "`heroku create ${YOUR_APP_NAME}`\n",
    "\n",
    "#### Push the docker image to heroku\n",
    "`heroku  container:push web -a ${YOUR_APP_NAME}`   \n",
    "`heroku container:release web -a ${YOUR_APP_NAME}`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call the model\n",
    "Before calling the model,let's understand how Tensorflow Serving RESTful API works:\n",
    "```\n",
    "POST http://host:port/<URI>:<VERB>\n",
    "\n",
    "URI: /v1/models/${MODEL_NAME}[/versions/${MODEL_VERSION}]\n",
    "VERB: classify|regress|predict\n",
    "```\n",
    "In our case the request will look like as:\n",
    "\n",
    "> `http://localhost:8501//v1/models/tf_servning_keras_mobilenetv2/versions/1:predict`\n",
    "\n",
    "\n",
    "Also, the JSON data that is sent to TensorFlow Model Server has to be structured in a very particular way\n",
    "```\n",
    "{\n",
    "  // (Optional) Serving signature to use.\n",
    "  // If unspecified default serving signature is used.\n",
    "  \"signature_name\": <string>,\n",
    "\n",
    "  // Input Tensors in row (\"instances\") or columnar (\"inputs\") format.\n",
    "  // A request can have either of them but NOT both.\n",
    "  \"instances\": <value>|<(nested)list>|<list-of-objects>\n",
    "  \"inputs\": <value>|<(nested)list>|<object>\n",
    "}\n",
    "```\n",
    "\n",
    "In order case:\n",
    "```\n",
    "{\n",
    "  \"signature_name\":'prediction',\n",
    "  \"instances\": [{\"images\":image.tolist()}]\n",
    "}\n",
    "```\n",
    "\n",
    "And you can see the full documentation about RESTful API in [Here](https://www.tensorflow.org/serving/api_rest). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I will show you how we can call the model.    \n",
    "However, before calling our model, we need to resize the image and convert them to float32 \n",
    "by using image_preprcess(image) function from part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from urllib import request\n",
    "from PIL import Image\n",
    "\n",
    "image_url = \"https://cdn.shopify.com/s/files/1/2029/4253/products/Damb_Back_2a3cc4cc-06c2-488e-8918-2e7a1cde3dfc_530x@2x.jpg\"\n",
    "image_path = f\"tmp/{image_url.split('/')[-1]}\"\n",
    "# download image\n",
    "with request.urlopen(url=image_url, timeout=10) as response:\n",
    "    data = response.read()\n",
    "    with open(image_path, 'wb') as f:\n",
    "        f.write(data)\n",
    "\n",
    "# convert image to grayscale.\n",
    "image = Image.open(image_path).convert('L')\n",
    "# resize the image to 28 28 to make sure it is similar to our dataset\n",
    "image.thumbnail((28,28))\n",
    "image = preprocess_image(np.array(image))\n",
    "print(image.shape)\n",
    "show_images([image])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you would like how we can call our model in `curl` here you go:\n",
    "```\n",
    "curl -X POST \\\n",
    "  https:// ${YOUR_APP_NAME}.herokuapp.com/v1/models/tf_servning_keras_mobilenetv2/versions/1:predict  \\\n",
    "  -d '{\"signature_name\":\"prediction\",\"instances\":[{\"images\":image.tolist()}]}'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\"\"\"\n",
    "NOTE:\n",
    "change https://tf-servning-keras-mobilenetv2.herokuapp.com to your url or \n",
    "if you ran the docker locally, then replace with http://localhost:8501\n",
    "\"\"\" \n",
    "url = \"https://tf-servning-keras-mobilenetv2.herokuapp.com\"\n",
    "full_url = f\"{url}/v1/models/tf_servning_keras_mobilenetv2/versions/1:predict\"\n",
    "data = {\"signature_name\":\"prediction\",\n",
    "        \"instances\":[{\"images\":image.tolist()}]}\n",
    "data = json.dumps(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "labels = ['T-shirt/top' ,'Trouser','Pullover','Dress','Coat','Sandal','Shirt','Sneaker','Bag', 'Ankle boot']\n",
    "try:\n",
    "    response = requests.post(full_url,data=data)\n",
    "    response = response.json()\n",
    "    highest_index = np.argmax(response['predictions'])\n",
    "    print(labels[highest_index])\n",
    "except:\n",
    "    print(sys.exc_info()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion \n",
    "\n",
    "In the in I hope you have enjoyed the tutorial, if you will to see more like this please following and clap :). And if you have any question or suggests, please leave them down in the comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# References:\n",
    "- [1] [Epoch vs Batch Size vs Iterations\n",
    "](https://towardsdatascience.com/epoch-vs-iterations-vs-batch-size-4dfb9c7ce9c9)\n",
    "- [2] [Gentlest Introduction to Tensorflow #1\n",
    "](https://medium.com/all-of-us-are-belong-to-machines/the-gentlest-introduction-to-tensorflow-248dc871a224)\n",
    "\n",
    "Here are some articles that it convert similar aspect cover in this article.\n",
    "\n",
    "- [Fashion-MNIST with tf.Keras](https://medium.com/tensorflow/hello-deep-learning-fashion-mnist-with-keras-50fcff8cd74a)\n",
    "- [A Comprehensive guide to Fine-tuning Deep Learning Models in Keras  ](https://flyyufelix.github.io/2016/10/03/fine-tuning-in-keras-part1.html)\n",
    "- [Transfer Learning and Fine Tuning: Let's discuss](https://www.linkedin.com/pulse/transfer-learning-fine-tuning-lets-discuss-arun-das/)\n",
    "- [Serving Image-Based Deep Learning Models with TensorFlow-Serving’s RESTful API](https://medium.com/@tmlabonte/serving-image-based-deep-learning-models-with-tensorflow-servings-restful-api-d365c16a7dc4)\n",
    "- [How to Setup Tensorflow Serving For Production](https://medium.com/@brianalois/how-to-setup-tensorflow-serving-for-production-3cc2abf7efa)\n",
    "- [How to Run Dockerized Apps on Heroku… and it’s pretty sweet] (https://medium.com/travis-on-docker/how-to-run-dockerized-apps-on-heroku-and-its-pretty-great-76e07e610e22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
