{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy a trained Keras MobileNet V2 model with Tensorflow Servning\n",
    "\n",
    "I am going to walk you through a complete a guideline of how to:\n",
    "\n",
    "**Part 1:**\n",
    "- Prepare data for training \n",
    "- Trained a deep learning model\n",
    "\n",
    "**Part 2:**\n",
    "- Serve the model with Tensorflow serving.\n",
    "- Deploy to [Heroku](https://www.heroku.com/).\n",
    "\n",
    "**In order to fully benefits from this services:**\n",
    "- You should be familiar with python.\n",
    "- You should have some understanding of what deep learning and neural network is.\n",
    "\n",
    "**Here is the list of what I am going to use:**\n",
    "- [Keras 2.2](https://keras.io/)\n",
    "- [Tensorflow 1.11](https://www.tensorflow.org/)\n",
    "- [Python 3.6](https://www.python.org/downloads/release/python-367/)\n",
    "- [scikit-image 0.14](https://scikit-image.org/)\n",
    "- [scikit-learn 0.19](http://scikit-learn.org/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "def show_images(images):\n",
    "    \"\"\"\n",
    "    images : numpy arrays\n",
    "    \"\"\"\n",
    "    n_images = len(images)\n",
    "    titles = ['(%d)' % i for i in range(1, n_images + 1)]\n",
    "    num = 5\n",
    "    iter_num = np.ceil(n_images / num).astype(int)\n",
    "    for i in range(iter_num):\n",
    "        fig = plt.figure()\n",
    "        sub_images = images[i * num:num * (i + 1)]\n",
    "        sub_titles = titles[i * num:num * (i + 1)]\n",
    "        for n, (image, title) in enumerate(zip(sub_images, sub_titles)):\n",
    "            a = fig.add_subplot(1, np.ceil(len(sub_images)), n + 1)\n",
    "            if image.ndim == 2:\n",
    "                plt.gray()\n",
    "            a.set_title(title, fontsize=15)\n",
    "            plt.imshow(image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data for training\n",
    "\n",
    "For the sake of simplicity, I am going to use the fashion mnist dataset because it is already optimized and labeled for a classification problem. \n",
    "Read more about the Fashion-MINST dataset in this paper [here](https://arxiv.org/abs/1708.07747)\n",
    "To download dataset and check other examples [here](https://github.com/zalandoresearch/fashion-mnist)\n",
    "\n",
    "It has 70,000 images, and each image is a grayscale of the size (28X28). \n",
    "which are categories into the following:\n",
    "\n",
    "|Lable|Description|  \n",
    "|-  |      -      |\n",
    "| 0 | T-shirt/top | \n",
    "| 1 | Trouser     | \n",
    "| 2 | Pullover    |  \n",
    "| 3 | Dress       | \n",
    "| 4 | Coat        | \n",
    "| 5 | Sandal      | \n",
    "| 6 | Shirt       |\n",
    "| 7 | Sneaker     | \n",
    "| 8 | Bag         | \n",
    "| 9 | Ankle boot  | \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start downloading the dataset. \n",
    "fortunately, many deep learning (DL) frameworks support fashion mnist dataset out of the box, \n",
    "including keras in our case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/MoAir/anaconda/envs/g/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28) y_train shape: (60000,)\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "# Load the fashion-mnist train data and test data\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "print(\"x_train shape:\", x_train.shape, \"y_train shape:\", y_train.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show samples of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(x_train[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default `keras.datasets.fashion_mnist.load_data()` is returning training and testing dataset. \n",
    "It is essential to split the dataset into training and  testing. \n",
    "Train data: This data actually to train the neural network (NN) \n",
    "Test: To valid the NN during the traning phase, by tuning and re-adjust the hyperparameters. \n",
    "hyperparameter is a parameter whose value is set before the learning process begins.(we will see them later)\n",
    "\n",
    "**However sometime we see train, valid and test dataset, why?**\n",
    "\n",
    "Glad you ask!\n",
    "\n",
    "After training the NN, we run the training NN against a our validation dataset \n",
    "to make sure that the model is generalized and is not overfitting. Overfitting basically means a model only predict the right result with the training data. However, if a model predicts the incorrectly result for the training data it's called underfitting. Here is a nice explination of [overfitting and underfitting](https://medium.com/greyatom/what-is-underfitting-and-overfitting-in-machine-learning-and-how-to-deal-with-it-6803a989c76).\n",
    "\n",
    "\n",
    "If the validation result was not pleased, we retrain the NN with different hyperparameters and we repeat this until we reach to a satisfied result. Now if the tranined and validation dataset have the result or score we want, we would think we are done. Not so fast!. Since we adjust the hyperparameters, we could lead the model to overfit in both train and valid dataset. To avoid this, we split the dataset into Train, Valid, and Test. \n",
    "After getting the desired score in both train and valid data, we run the model against the test dataset. Usually the test dataset should be closed to the validation result. For example getting 90% in valid data, and 87% in testing is acceptable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data normalization\n",
    "Normalize the data dimensions so that they are of approximately the same scale.In general, normalization makes very deep NN easier to train, special in Convolutional and Recurrent neural network.\n",
    "\n",
    "Here is a nice explanation [video](https://www.coursera.org/lecture/deep-neural-network/normalizing-activations-in-a-network-4ptp2) and an [article](https://medium.com/@darrenyaoyao.huang/why-we-need-normalization-in-deep-learning-from-batch-normalization-to-group-normalization-d06ea0e59c17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_x_train = x_train.astype('float32') / 255\n",
    "norm_x_test = x_test.astype('float32') / 255\n",
    "# dsiplay images\n",
    "show_images(norm_x_train[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert labels (y_train and y_test) to one hot encoding\n",
    "A one hot encoding is a representation of categorical variables as binary vectors.\n",
    "\n",
    "[Here is the full explanation](https://machinelearningmastery.com/how-to-one-hot-encode-sequence-data-in-python/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoded_y_train = keras.utils.to_categorical(y_train, num_classes=10, dtype='float32')\n",
    "encoded_y_test = keras.utils.to_categorical(y_test, num_classes=10, dtype='float32')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resize images\n",
    "\n",
    "Because we are going to use [MobileNet V2](https://keras.io/applications/#mobilenetv2) model, which accept (96 , 96 ,3) format as minimum image size.\n",
    "\n",
    "We need to resize the image and convert to 3 channel (RGB.\n",
    "from (28 X 28) to (96 X 96 X 3). \n",
    "\n",
    "Here are the supported formats;\n",
    "> If imagenet weights are being loaded, input must have a static square shape(one of (96, 96), (128, 128), (160, 160),(192, 192), or (224, 224))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from skimage.transform import resize\n",
    "\n",
    "target_size = 96\n",
    "def preprocess_image(x):\n",
    "    # convert to 3 channel\n",
    "    x = resize(x, (target_size, target_size),\n",
    "            mode='constant',\n",
    "            anti_aliasing=False)\n",
    "    x = np.stack((x,)*3, axis=-1) \n",
    "    return x.astype(np.float32)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we resize all the training and testing data, it will eat up a lot of memory resources; therefore, we are going to use generator.   \n",
    "[Python Generators](https://www.programiz.com/python-programming/generator) are a simple way of creating iterators. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "def load_data_generator(x,y, batch_size=64):\n",
    "    num_samples = x.shape[0]\n",
    "    while 1:  # Loop forever so the generator never terminates\n",
    "        try:\n",
    "            shuffle(x)\n",
    "            for offset in range(0, num_samples, batch_size):\n",
    "                x_data =  [preprocess_image(img) for img in x[offset:offset + batch_size]]\n",
    "                y_data = y[offset:offset + batch_size]\n",
    "                # convert to numpy array since this what keras required\n",
    "                yield shuffle(np.array(x_data), np.array(y_data))\n",
    "        except Exception as err:\n",
    "            print(err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a deep learning Model\n",
    "\n",
    "### Transfer Learning\n",
    "Transfer learning in deep learning means to transfer knownlady from one domain to another similar one.\n",
    "In our example, I have chosen MobileNet V2 model because it’s faster to train and small in size. [Documentation for Individual Models](https://keras.io/applications/#documentation-for-individual-models).\n",
    "MobileNet is pre-trained with [ImageNet dataset](http://www.image-net.org/) with 1000 classes or categories. \n",
    "We are using this model and re-train it with our dataset and 10 classes only. Because we are using pre-trained model that has been trained on different dataset (domain), then we are using transfer learning :). Here is a nice article example it in more details. [A Gentle Introduction to Transfer Learning for Deep Learning](https://machinelearningmastery.com/transfer-learning-for-deep-learning/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can freez the MobileNet trained layers and only trained the layers we added. \n",
    "by the following:\n",
    "```\n",
    "for layer in app_model.layers:\n",
    "        layer.trainable = False \n",
    "```\n",
    "\n",
    "**When do I need to re-train the trainable layers?**   \n",
    "When you have large dataset to train, in our case we just have enough data, however,    \n",
    "I trained with `layer.trainable = True` you can try the other way around and see the result.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.applications.mobilenetv2 import MobileNetV2\n",
    "from keras.layers import Dense, Input, Dropout\n",
    "from keras.models import Model\n",
    "\n",
    "def build_model( ):\n",
    "    input_tensor = Input(shape=(target_size, target_size, 3))\n",
    "    app_model = MobileNetV2(\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        input_tensor=input_tensor,\n",
    "        input_shape=(target_size, target_size, 3),\n",
    "        pooling='avg')\n",
    "\n",
    "    for layer in app_model.layers:\n",
    "        layer.trainable = True  # trainable has to be false in order to freez the layers\n",
    "        \n",
    "    op = Dense(256, activation='relu')(app_model.output)\n",
    "    op = Dropout(.25)(op)\n",
    "    outputs = Dense(10, activation='softmax')(op)\n",
    "\n",
    "    model = Model(inputs=input_tensor, outputs=outputs)\n",
    "\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build and compile the model\n",
    "The most interesting thing in our model is the last layer\n",
    "```\n",
    " outputs = Dense(10, activation='softmax')(op)\n",
    "```\n",
    "10 indicates that the final result should have a change of (10,) which reprease our 10 classes\n",
    "\n",
    "**softmax:** calculates a probability for every possible class.   \n",
    "**activation='softmax'**: return the highest probability;    \n",
    "for example, if `Coat` is the highest probability then the result would be something like [0,0,0,0,1,0,0,0,0,0] with `1` in index 5 indicate `Coat`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = build_model()\n",
    "model.compile(optimizer=keras.optimizers.Adam(),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train\n",
    "Now we are ready to train the model.\n",
    "\n",
    "**epochs**: \n",
    " > One Epoch is when an ENTIRE dataset is passed forward and backward through the neural network only ONCE. [1]\n",
    "\n",
    "**Batch Size**\n",
    "> Total number of training examples present in a single batch.[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = load_data_generator(norm_x_train, encoded_y_train, batch_size=64)\n",
    "\n",
    "model.fit_generator(\n",
    "    generator=train_generator,\n",
    "    steps_per_epoch=900,\n",
    "    verbose=1,\n",
    "    epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_generator = load_data_generator(norm_x_test, encoded_y_test, batch_size=64)\n",
    "model.evaluate_generator(generator=test_generator,steps=900,verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model\n",
    "Save the model to be reused in part 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_name = \"tf_servning_keras_mobilenetv2\"\n",
    "model.save(f\"models/{model_name}.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(for medium only)\n",
    "# Conclusion \n",
    "In the end of this part, here what we have learning.\n",
    "We were able to prepare a the fashion dataset for MobileNetV2 model. \n",
    "And use MobileNet as our base model for transfer learning.\n",
    "And we got `94%` accuracy in training and  `86%` accuracy in testing.\n",
    "In part 2 we are going save the model to a format the tensorflow serving can read. \n",
    "and then deploy to heroku. Thank you for ready and If you have any question or suggests, \n",
    "please leave them down in the comments\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Makes Model ready to tensorflow serving\n",
    "\n",
    "### Tensorflow serving \n",
    "[TensorFlow Serving](https://www.tensorflow.org/serving/overview) is a flexible, high-performance serving system for machine learning models, designed for **production** environments.\n",
    "\n",
    "\n",
    "#### Load the saved model from Part 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model(f\"models/{model_name}.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build & Save model to be tensorflow serving ready\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: models/export/tf_servning_keras_mobilenetv2/1/saved_model.pb\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "b'models/export/tf_servning_keras_mobilenetv2/1/saved_model.pb'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "# Import the libraries needed for saving models\n",
    "# Note that in some other tutorials these are framed as coming from tensorflow_serving_api which is no longer correct\n",
    "from tensorflow.python.saved_model import builder as saved_model_builder\n",
    "from tensorflow.python.saved_model import tag_constants, signature_constants, signature_def_utils_impl\n",
    "\n",
    "# images will be the input key name\n",
    "# scores will be the out key name\n",
    "prediction_signature = tf.saved_model.signature_def_utils.predict_signature_def(\n",
    "    {\n",
    "    \"images\": model.input\n",
    "    }, {\n",
    "    \"scores\": model.output\n",
    "    })\n",
    "\n",
    "# export_path is a directory in which the model will be created\n",
    "export_path = os.path.join(\n",
    "    tf.compat.as_bytes('models/export/{}'.format(model_name)),\n",
    "    tf.compat.as_bytes('1'))\n",
    "\n",
    "builder = saved_model_builder.SavedModelBuilder(export_path)\n",
    "\n",
    "sess = keras.backend.get_session()\n",
    "\n",
    "# Add the meta_graph and the variables to the builder\n",
    "builder.add_meta_graph_and_variables(\n",
    "    sess, [tag_constants.SERVING],\n",
    "    signature_def_map={\n",
    "        'prediction': prediction_signature,\n",
    "    })\n",
    "# save the graph\n",
    "builder.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up Heroku & Docker\n",
    "Nice work, almost there, now we are going to deploy our model to heroku, \n",
    "so we can call it.\n",
    "\n",
    "[Heroku](https://www.heroku.com/) is a cloud platform as a service supporting several programming languages.\n",
    "[docker]() allows us to package all the necessary libraries and programer into a container. Here is a nice [Introduction to Containers, VMs and Docker](https://medium.freecodecamp.org/a-beginner-friendly-introduction-to-containers-vms-and-docker-79a9e3e119b)\n",
    "\n",
    "\n",
    "- [Install docker for macOS and windows](https://www.docker.com/products/docker-desktop)\n",
    "- A little more work for Ubuntu users but still straightforward [Install docker for Ubuntu](https://docs.docker.com/install/linux/docker-ce/ubuntu/#upgrade-docker-ce)\n",
    "- [Signup to Heroku](https://signup.heroku.com/)\n",
    "- [Install heroku-cli](https://devcenter.heroku.com/articles/heroku-cli#download-and-install)\n",
    "\n",
    "### After you have installed docker and heroku-cli.\n",
    "\n",
    "Run the following to make sure docker & heroku have been installed correctly\n",
    "```\n",
    "> docker ps \n",
    "CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES\n",
    "\n",
    "> heroku --version\n",
    "heroku/7.18.3 darwin-x64 node-v10.12.0\n",
    "\n",
    "# make sure to loign to your heroku account\n",
    "heroku login\n",
    "# Output should have:   \n",
    "Logged in as xxxxx@xxx.xx\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy the model to Heroku\n",
    "\n",
    "#### Download tensorflow serving image from `hub.docker.com`\n",
    "Because tensorflow serving docker image was not optimized for heroku. \n",
    "\n",
    "I have created a dockerfile that following heroku instructure.\n",
    "cleck [here](https://github.com/malnakli/ML/tf_servning_keras_mobilenetv2/Dockerfile) to look at.\n",
    "Also I have pushed the a docker image that ready to deply to heroku, which already have the trained model. \n",
    "`docker pull malnakli/ml:tf-serving-heroku-1.11`\n",
    "\n",
    "However, I will walk you through how to do build the image that has your trained model\n",
    "\n",
    "Run the following:\n",
    "`docker build -t tf-serving-heroku-1.11 .`\n",
    "\n",
    "Once the image build. you can run it locally.\n",
    "`docker run -p 8501:8501 -e PORT=8501 -t tf-serving-heroku-1.11`\n",
    "\n",
    "If you see the following the last output, then it works.\n",
    "```\n",
    "2018-10-27 21:17:47.515120: I tensorflow_serving/model_servers/server.cc:301] Exporting HTTP/REST API at:localhost:8501 ...\n",
    "```\n",
    "#### Deploy\n",
    "\n",
    "##### Log in to Container Registry:\n",
    "`heroku container:login`\n",
    "\n",
    "##### Create a heroku app\n",
    "`heroku create ${YOUR_APP_NAME}`\n",
    "\n",
    "#### Push the docker image to heroku\n",
    "`heroku  container:push web -a ${YOUR_APP_NAME}`   \n",
    "`heroku container:release web -a ${YOUR_APP_NAME}`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call the model\n",
    "Tensorflow serving RESTful API syntax as following:\n",
    "```\n",
    "POST http://host:port/<URI>:<VERB>\n",
    "\n",
    "URI: /v1/models/${MODEL_NAME}[/versions/${MODEL_VERSION}]\n",
    "VERB: classify|regress|predict\n",
    "```\n",
    "And you can see the full documentation about RESTful API in [Here](https://www.tensorflow.org/serving/api_rest). \n",
    "\n",
    "In our case the reqest will look like as:\n",
    "\n",
    "> `http://localhost:8501//v1/models/tf_servning_keras_mobilenetv2/versions/1:predict`\n",
    "\n",
    "Keep in mind that JSON data sent to TensorFlow Model Server has to be structured in a very particular way\n",
    "```\n",
    "{\n",
    "  // (Optional) Serving signature to use.\n",
    "  // If unspecifed default serving signature is used.\n",
    "  \"signature_name\": <string>,\n",
    "\n",
    "  // Input Tensors in row (\"instances\") or columnar (\"inputs\") format.\n",
    "  // A request can have either of them but NOT both.\n",
    "  \"instances\": <value>|<(nested)list>|<list-of-objects>\n",
    "  \"inputs\": <value>|<(nested)list>|<object>\n",
    "}\n",
    "```\n",
    "\n",
    "Now I will show you how we can call the model. However, before calling our model, we need to resize the image and convert them no float32 image_preprcess(image) function from part 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96, 96, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAEKCAYAAADdIIPUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKCr8QhTK/wceR2x1UzycJgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c45e7be80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from urllib import request\n",
    "from PIL import Image\n",
    "\n",
    "image_url = \"https://cdn.shopify.com/s/files/1/2029/4253/products/Damb_Back_2a3cc4cc-06c2-488e-8918-2e7a1cde3dfc_530x@2x.jpg\"\n",
    "image_path = f\"tmp/{image_url.split('/')[-1]}\"\n",
    "# download image\n",
    "with request.urlopen(url=image_url, timeout=10) as response:\n",
    "    data = response.read()\n",
    "    with open(image_path, 'wb') as f:\n",
    "        f.write(data)\n",
    "\n",
    "# convert image to grayscale.\n",
    "image = Image.open(image_path).convert('L')\n",
    "# resize the image to 28 28 to make sure it is similar to our dataset\n",
    "image.thumbnail((28,28))\n",
    "image = preprocess_image(np.array(image))\n",
    "print(image.shape)\n",
    "show_images([image])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our finall call in `curl` will look like as:\n",
    "```\n",
    "curl -X POST \\\n",
    "  https:// ${YOUR_APP_NAME}.herokuapp.com/v1/models/tf_servning_keras_mobilenetv2/versions/1:predict  \\\n",
    "  -d '{\"signature_name\":\"prediction\",\"instances\":[{\"images\":image.tolist()}]}'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "# change https://tf-servning-keras-mobilenetv2.herokuapp.com to your url or \n",
    "# if you ran the docker locally, then replace with http://localhost:8501\n",
    "url = f\"https://tf-servning-keras-mobilenetv2.herokuapp.com/v1/models/tf_servning_keras_mobilenetv2/versions/1:predict\"\n",
    "data = {\"signature_name\":\"prediction\",\n",
    "        \"instances\":[{\"images\":image.tolist()}]}\n",
    "data = json.dumps(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-shirt/top\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "labels = ['T-shirt/top' ,'Trouser','Pullover','Dress','Coat','Sandal','Shirt','Sneaker','Bag', 'Ankle boot']\n",
    "try:\n",
    "    response = requests.post(url,data=data)\n",
    "    response = response.json()\n",
    "    highest_index = np.argmax(response['predictions'])\n",
    "    print(labels[highest_index])\n",
    "except:\n",
    "    print(sys.exc_info()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for medium only\n",
    "# Conclusion \n",
    "\n",
    "### TODO \n",
    "Thank you for ready and If you have any question or suggests, \n",
    "please leave them down in the comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# References:\n",
    "- [1] https://towardsdatascience.com/epoch-vs-iterations-vs-batch-size-4dfb9c7ce9c9\n",
    "- https://medium.com/@tmlabonte/serving-image-based-deep-learning-models-with-tensorflow-servings-restful-api-d365c16a7dc4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
